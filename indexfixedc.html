<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claude Roleplay with Fixed Voice Detection</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        async function testConnection() {
            if (corsMethod === 'demo') {
                showStatus('‚úÖ Demo mode - all systems ready!', 'success');
                addMessage('Demo mode test: Hybrid voice detection with contextual analysis!');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                return;
            }

            const claudeKey = document.getElementById('claudeKey').value.trim();
            if (!claudeKey) {
                showStatus('Please enter Claude API key first', 'error');
                return;
            }
            
            // Validate API key format
            if (!claudeKey.startsWith('sk-ant-')) {
                showStatus('‚ùå Invalid Claude API key format. Should start with "sk-ant-"', 'error');
                return;
            }
            
            showStatus('Testing API connections...', 'info');
            addDebugInfo(`üîë Testing with Claude API key: ${claudeKey.substring(0, 12)}...`);
            
            try {
                const claudeResponse = await makeClaudeRequest('Say hello and then add a coach comment using natural language', 'Test the coach detection by responding as character then coach.');
                
                if (claudeResponse) {
                    showStatus('‚úÖ Claude API working!', 'success');
                    addMessage(claudeResponse);
                    updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                    addDebugInfo(`‚úÖ Claude response received: ${claudeResponse.length} characters`);
                }
                
                const elevenKey = document.getElementById('elevenKey').value.trim();
                if (elevenKey) {
                    addDebugInfo(`üîë Testing ElevenLabs key: ${elevenKey.substring(0, 8)}...`);
                    try {
                        const sections = hybridSplitCoachAndCharacter(claudeResponse);
                        await playMultipleVoiceSections(sections);
                        showStatus('‚úÖ Both APIs working perfectly!', 'success');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                    } catch (voiceError) {
                        addDebugInfo(`‚ùå ElevenLabs error: ${voiceError.message}`);
                        showStatus(`Claude works, but ElevenLabs failed: ${voiceError.message}`, 'error');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                    }
                } else {
                    showStatus('‚úÖ Claude API working! Add ElevenLabs key for voice.', 'success');
                }
            } catch (error) {
                addDebugInfo(`üö® TEST CONNECTION ERROR: ${error.message}`);
                showStatus(`‚ùå API test failed: ${error.message}`, 'error');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'error');
                
                // Provide specific troubleshooting
                if (error.message.includes('Network connection failed')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Check your internet connection');
                } else if (error.message.includes('401') || error.message.includes('403')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Invalid API key - check your Claude API key');
                } else if (error.message.includes('429')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Rate limited - wait a moment and try again');
                } else {
                    addDebugInfo('üí° TROUBLESHOOTING: Try switching to Demo mode to test the interface');
                }
            }
        }
        
        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        h1 {
            text-align: center;
            color: #4a5568;
            margin-bottom: 30px;
        }
        
        .api-setup {
            background: #f7fafc;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            border-left: 4px solid #4299e1;
        }
        
        .input-group {
            margin-bottom: 15px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 600;
            color: #2d3748;
        }
        
        input, textarea, select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 14px;
            transition: border-color 0.3s;
            box-sizing: border-box;
        }
        
        input:focus, textarea:focus, select:focus {
            outline: none;
            border-color: #4299e1;
        }
        
        button {
            background: linear-gradient(135deg, #4299e1, #3182ce);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            margin: 5px;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(66, 153, 225, 0.3);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        
        button.recording {
            background: linear-gradient(135deg, #e53e3e, #c53030);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .speech-indicator {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 8px;
            padding: 10px;
            margin: 10px 0;
            text-align: center;
            font-weight: 500;
            color: #856404;
        }
        
        .chat-container {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            max-height: 400px;
            overflow-y: auto;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
        }
        
        .user-message {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
        }
        
        .claude-message {
            background: #f3e5f5;
            border-left: 4px solid #9c27b0;
        }
        
        .coach-section {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            margin: 5px 0;
            padding: 8px;
            border-radius: 5px;
            font-style: italic;
        }
        
        .character-section {
            background: #e8f5e8;
            border-left: 4px solid #4caf50;
            margin: 5px 0;
            padding: 8px;
            border-radius: 5px;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .status {
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-weight: 500;
        }
        
        .status.success { background: #d4e6f1; color: #1565c0; }
        .status.error { background: #ffebee; color: #c62828; }
        .status.info { background: #e8f5e8; color: #2e7d32; }
        
        .audio-controls {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-top: 10px;
        }
        
        audio {
            flex: 1;
            max-width: 300px;
        }
        
        .cors-info {
            background: #e8f5e8;
            border: 1px solid #4caf50;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            color: #2e7d32;
        }
        
        .proxy-selector {
            margin: 15px 0;
        }
        
        .proxy-option {
            margin: 8px 0;
            padding: 10px;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
        }
        
        .demo-mode {
            background: #e1f5fe;
            border: 1px solid #0288d1;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        
        .voice-selector {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 8px;
            margin-top: 10px;
        }
        
        .voice-option {
            padding: 8px 12px;
            background: #f0f0f0;
            border: 1px solid #ddd;
            border-radius: 5px;
            cursor: pointer;
            text-align: center;
            transition: background-color 0.2s;
            font-size: 12px;
        }
        
        .voice-option:hover {
            background: #e0e0e0;
        }
        
        .voice-option.selected {
            background: #4299e1;
            color: white;
        }
        
        .voice-option.coach-selected {
            background: #9f7aea;
            color: white;
        }
        
        .microphone-help {
            background: #ffebee;
            border: 1px solid #f44336;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #c62828;
        }
        
        .api-help {
            background: #fff3cd;
            border: 1px solid #ffc107;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #856404;
        }
        
        .voice-section {
            background: #f8f9ff;
            border: 1px solid #d0d0ff;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        
        .connection-status {
            display: flex;
            gap: 10px;
            align-items: center;
            margin: 10px 0;
        }
        
        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ccc;
        }
        
        .status-indicator.connected {
            background: #4caf50;
            animation: pulse-green 2s infinite;
        }
        
        .status-indicator.error {
            background: #f44336;
        }
        
        @keyframes pulse-green {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .coach-instruction {
            background: #fff9e6;
            border: 1px solid #ffc107;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #8b5000;
        }
        
        .debug-info {
            background: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            font-family: monospace;
            font-size: 12px;
            max-height: 150px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ Claude Roleplay with Fixed Voice Detection</h1>
        
        <div class="cors-info">
            <h3>üéØ Hybrid Voice Detection System</h3>
            <p><strong>Smart contextual analysis + manual override buttons.</strong> Prioritizes authentic conversation flow while giving you control when detection fails.</p>
        </div>
        
        <div class="connection-status">
            <div class="status-indicator" id="corsStatus"></div>
            <span>CORS Proxy Status</span>
            <div class="status-indicator" id="claudeStatus"></div>
            <span>Claude API</span>
            <div class="status-indicator" id="elevenStatus"></div>
            <span>ElevenLabs API</span>
        </div>
        
        <div class="proxy-selector">
            <h3>üîß CORS Solutions</h3>
            <div class="proxy-option">
                <label>
                    <input type="radio" name="corsMethod" value="corsfix" checked> 
                    <strong>Corsfix Professional (Recommended)</strong>
                </label>
                <small>Professional service with reliable API access</small>
            </div>
            <div class="proxy-option">
                <label>
                    <input type="radio" name="corsMethod" value="demo"> 
                    <strong>Demo Mode (For Testing)</strong>
                </label>
                <small>Test interface with mock responses</small>
            </div>
        </div>
        
        <div class="demo-mode" id="demoInfo" style="display: none;">
            <h3>üéØ Demo Mode Active</h3>
            <p>This mode simulates API responses with fixed voice detection. Switch to Corsfix above to use real APIs.</p>
        </div>
        
        <div class="api-help">
            <h3>üìã API Key Instructions</h3>
            <p><strong>Claude API:</strong> Get your key from <a href="https://console.anthropic.com" target="_blank">console.anthropic.com</a> ‚Üí API Keys</p>
            <p><strong>ElevenLabs API:</strong> Get your key from <a href="https://elevenlabs.io/app/speech-synthesis" target="_blank">elevenlabs.io</a> ‚Üí Profile ‚Üí API Keys</p>
        </div>
        
        <div class="microphone-help" id="microphoneHelp" style="display: none;">
            <h3>üé§ Microphone Permission Help</h3>
            <p><strong>If speech recognition doesn't work:</strong></p>
            <ol>
                <li><strong>HTTPS Required:</strong> Upload to GitHub Pages, Netlify, or Vercel for microphone access</li>
                <li><strong>Chrome/Edge:</strong> Click the üé§ icon in address bar ‚Üí Allow microphone</li>
                <li><strong>Manual check:</strong> <button onclick="checkMicrophonePermission()" style="display: inline; padding: 5px 10px; margin: 0;">Test Microphone Access</button></li>
            </ol>
        </div>
        
        <div class="api-setup" id="apiSetup">
            <h3>API Configuration</h3>
            <div class="input-group">
                <label for="claudeKey">Claude API Key:</label>
                <input type="password" id="claudeKey" placeholder="sk-ant-... (get from console.anthropic.com)">
            </div>
            <div class="input-group">
                <label for="elevenKey">ElevenLabs API Key:</label>
                <input type="password" id="elevenKey" placeholder="Get from elevenlabs.io/app/speech-synthesis">
            </div>
            
            <div class="voice-section">
                <h4>üéØ Character Voice Selection:</h4>
                <label>Character Voice (for roleplay scenarios):</label>
                <div class="voice-selector" id="characterVoices">
                    <div class="voice-option selected" data-voice="pNInz6obpgDQGcFmaJgB">Adam</div>
                    <div class="voice-option" data-voice="21m00Tcm4TlvDq8ikWAM">Rachel</div>
                    <div class="voice-option" data-voice="AZnzlk1XvdvUeBnXmlld">Domi</div>
                    <div class="voice-option" data-voice="EXAVITQu4vr4xnSDxMaL">Bella</div>
                    <div class="voice-option" data-voice="ErXwobaYiN019PkySvjV">Antoni</div>
                    <div class="voice-option" data-voice="MF3mGyEYCl7XYWbV9V6O">Elli</div>
                </div>
                <input type="text" id="customCharacterVoice" placeholder="Or enter custom Character Voice ID" style="margin-top: 10px;">
            </div>
            
            <div class="voice-section">
                <h4>üéì Coach Voice Selection:</h4>
                <label>Coach Voice (detected automatically in responses):</label>
                <div class="voice-selector" id="coachVoices">
                    <div class="voice-option coach-selected" data-voice="21m00Tcm4TlvDq8ikWAM">Rachel</div>
                    <div class="voice-option" data-voice="pNInz6obpgDQGcFmaJgB">Adam</div>
                    <div class="voice-option" data-voice="AZnzlk1XvdvUeBnXmlld">Domi</div>
                    <div class="voice-option" data-voice="EXAVITQu4vr4xnSDxMaL">Bella</div>
                    <div class="voice-option" data-voice="ErXwobaYiN019PkySvjV">Antoni</div>
                    <div class="voice-option" data-voice="MF3mGyEYCl7XYWbV9V6O">Elli</div>
                </div>
                <input type="text" id="customCoachVoice" placeholder="Or enter custom Coach Voice ID" style="margin-top: 10px;">
            </div>
        </div>
        
        <div class="coach-instruction">
            <h4>üéØ Hybrid Voice Detection System:</h4>
            <ul>
                <li><strong>Smart Contextual Analysis:</strong> Analyzes conversation flow, emotional shifts, and teaching moments</li>
                <li><strong>Natural Coach Detection:</strong> Catches coaching language without forcing artificial markers</li>
                <li><strong>Manual Override Controls:</strong> Yellow buttons appear when you can force specific voice</li>
                <li><strong>Conversation Context:</strong> Learns from your dialogue patterns and emotional states</li>
                <li><strong>Authentic Feel:</strong> Prioritizes natural conversation flow over explicit markers</li>
                <li><strong>Backup Pattern Detection:</strong> Still catches explicit **COACH:** markers when used</li>
            </ul>
            <p><strong>How it works:</strong> The system analyzes conversation context, emotional shifts, teaching intent, and coaching activities to intelligently switch voices while keeping dialogue natural.</p>
        </div>
        
        <div class="input-group">
            <label for="scenario">Roleplay Scenario & Coach Instructions:</label>
            <textarea id="scenario" rows="4" placeholder="e.g., 'You are a friendly wizard helping me on a quest. You also act as a coach who steps in periodically to give me guidance on my roleplay choices. When coaching, ALWAYS use clear markers like **COACH:** or [Coach] or *Coach mode:* to indicate when you're stepping out of character.'"></textarea>
        </div>
        
        <div class="input-group">
            <label for="userInput">Your Message:</label>
            <textarea id="userInput" rows="2" placeholder="Type your message here..."></textarea>
        </div>
        
        <div class="controls">
            <button onclick="sendMessage()">Send & Speak</button>
            <button onclick="toggleSpeechRecognition()" id="speechBtn">üé§ Start Speaking</button>
            <button onclick="stopAudio()">Stop Audio</button>
            <button onclick="clearChat()">Clear Chat</button>
            <button onclick="testConnection()">Test APIs</button>
            <button onclick="testCorsProxy()">Test CORS Proxy</button>
            <button onclick="testVoiceDetection()">Test Voice Detection</button>
            <button onclick="toggleDebug()">Toggle Debug</button>
        </div>
        
        <div class="controls" id="voiceOverrideControls" style="background: #fff3cd; padding: 10px; border-radius: 5px; margin: 10px 0;">
            <strong>üéöÔ∏è Voice Override Controls:</strong> Last response was <span id="detectedVoice">AUTO</span> voice.
            <button onclick="forceVoice('coach')" style="background: #9f7aea;">üéì Replay as Coach</button>
            <button onclick="forceVoice('character')" style="background: #4299e1;">üé≠ Replay as Character</button>
            <button onclick="useDetectedVoice()" style="background: #48bb78;">‚úÖ Auto Detect</button>
        </div>
        
        <div id="status"></div>
        
        <div id="speechIndicator" class="speech-indicator" style="display: none;">
            üé§ Listening... Speak now, then click "Stop Speaking" when done.
        </div>
        
        <div class="debug-info" id="debugInfo" style="display: none;">
            <strong>Voice Detection Debug:</strong>
            <div id="debugContent"></div>
        </div>
        
        <div class="chat-container" id="chatContainer">
            <p style="text-align: center; color: #666;">Set up your scenario with coach instructions, then start chatting!</p>
        </div>
        
        <div class="audio-controls" id="audioControls" style="display: none;">
            <audio controls id="audioPlayer"></audio>
        </div>
    </div>

    <script>
        let currentAudio = null;
        let conversationHistory = [];
        let recognition = null;
        let isRecording = false;
        let selectedCharacterVoice = 'pNInz6obpgDQGcFmaJgB';
        let selectedCoachVoice = '21m00Tcm4TlvDq8ikWAM';
        let corsMethod = 'corsfix';
        let debugMode = false;
        let conversationTurn = 0;
        let lastUserMessage = '';
        let lastClaudeResponse = '';
        let pendingVoiceOverride = null; // For manual voice selection

        function updateStatusIndicator(element, status) {
            if (element) {
                element.className = `status-indicator ${status}`;
            }
        }

        function showStatus(message, type = 'info') {
            const status = document.getElementById('status');
            if (status) {
                status.className = `status ${type}`;
                status.textContent = message;
                setTimeout(() => status.textContent = '', 10000);
            }
        }

        function addDebugInfo(message) {
            if (debugMode) {
                const debugContent = document.getElementById('debugContent');
                if (debugContent) {
                    const timestamp = new Date().toLocaleTimeString();
                    debugContent.innerHTML += `[${timestamp}] ${message}<br>`;
                    debugContent.scrollTop = debugContent.scrollHeight;
                }
            }
            console.log('üîç DEBUG:', message);
        }

        function testVoiceDetection() {
            const testPhrases = [
                "I am a female coach! My goal is to help guide you through these tricky conversations.",
                "Hi, I'm the Coach again. You've made a good observation.",
                "**COACH:** Let me step in here to help you with this technique.",
                "[COACH] This is exactly what we need to practice.",
                "Would you like to watch that 5-minute video I mentioned?",
                "Let me help you with a better approach to this situation.",
                "Here's a technique that might be useful for you.",
                "Hi there, what you just said really ticks me off." // Should be character
            ];
            
            addDebugInfo("=== TESTING HYBRID VOICE DETECTION ===");
            
            const mockContext = {
                lastUserMessage: "I'm confused about what to do",
                conversationTurn: 5,
                recentHistory: []
            };
            
            testPhrases.forEach((phrase, i) => {
                const isCoach = hybridDetectCoachSpeaking(phrase, mockContext);
                const expected = i < 7 ? "COACH" : "CHARACTER"; // Last one should be character
                const result = isCoach ? "COACH" : "CHARACTER";
                const status = (result === expected) ? "‚úÖ CORRECT" : "‚ùå WRONG";
                
                addDebugInfo(`Test ${i+1}: ${status} - "${phrase.substring(0, 40)}..." ‚Üí ${result} (expected: ${expected})`);
            });
            
            addDebugInfo("=== CONTEXTUAL SCENARIOS ===");
            
            // Test contextual detection
            const contextualTests = [
                {
                    context: { lastUserMessage: "I'm really confused", conversationTurn: 3 },
                    response: "Let me explain this in a different way.",
                    expected: "COACH"
                },
                {
                    context: { lastUserMessage: "That made me angry", conversationTurn: 2 },
                    response: "Here's a better technique for handling anger.",
                    expected: "COACH"
                },
                {
                    context: { lastUserMessage: "Hello there", conversationTurn: 1 },
                    response: "Hey! How's your day going?",
                    expected: "CHARACTER"
                }
            ];
            
            contextualTests.forEach((test, i) => {
                const isCoach = hybridDetectCoachSpeaking(test.response, test.context);
                const result = isCoach ? "COACH" : "CHARACTER";
                const status = (result === test.expected) ? "‚úÖ CORRECT" : "‚ùå WRONG";
                
                addDebugInfo(`Context ${i+1}: ${status} - User: "${test.context.lastUserMessage}" ‚Üí Claude: "${test.response}" ‚Üí ${result}`);
            });
            
            showStatus('Hybrid voice detection test completed - check debug log', 'info');
        }

        async function testCorsProxy() {
            showStatus('Testing CORS proxy connection...', 'info');
            addDebugInfo('üß™ TESTING CORS PROXY CONNECTION');
            
            try {
                // Test with a simple public API first
                const testUrl = 'https://httpbin.org/get';
                const proxyUrl = `https://proxy.corsfix.com/?${testUrl}`;
                
                addDebugInfo(`üîó Testing proxy with: ${proxyUrl}`);
                
                const response = await fetch(proxyUrl, {
                    method: 'GET',
                    headers: {
                        "x-corsfix-headers": JSON.stringify({
                            Origin: "",
                        }),
                    }
                });
                
                addDebugInfo(`üì° Proxy response: ${response.status} ${response.statusText}`);
                
                if (response.ok) {
                    const data = await response.json();
                    addDebugInfo(`‚úÖ CORS proxy is working! Test response received.`);
                    showStatus('‚úÖ CORS proxy is working fine', 'success');
                    updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
                } else {
                    throw new Error(`Proxy returned ${response.status}: ${response.statusText}`);
                }
                
            } catch (error) {
                addDebugInfo(`‚ùå CORS PROXY TEST FAILED: ${error.message}`);
                showStatus(`‚ùå CORS proxy test failed: ${error.message}`, 'error');
                updateStatusIndicator(document.getElementById('corsStatus'), 'error');
                
                if (error.message.includes('Failed to fetch')) {
                    addDebugInfo('üí° This suggests a network connectivity issue');
                    showStatus('üí° Network issue detected - check your internet connection', 'error');
                }
            }
        }

        function toggleDebug() {
            debugMode = !debugMode;
            const debugInfo = document.getElementById('debugInfo');
            if (debugInfo) {
                debugInfo.style.display = debugMode ? 'block' : 'none';
                if (debugMode) {
                    addDebugInfo('Debug mode enabled - voice detection info will appear here');
                }
            }
        }

        function addMessage(content, isUser = false) {
            const chatContainer = document.getElementById('chatContainer');
            if (!chatContainer) return;
            
            if (isUser) {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'message user-message';
                messageDiv.innerHTML = `<strong>You:</strong> ${content}`;
                chatContainer.appendChild(messageDiv);
            } else {
                // Split and display coach/character sections visually
                const sections = hybridSplitCoachAndCharacter(content);
                const messageWrapper = document.createElement('div');
                messageWrapper.className = 'message claude-message';
                messageWrapper.innerHTML = '<strong>Claude:</strong>';
                
                sections.forEach(section => {
                    const sectionDiv = document.createElement('div');
                    sectionDiv.className = section.type === 'coach' ? 'coach-section' : 'character-section';
                    sectionDiv.innerHTML = `<strong>${section.type === 'coach' ? 'üéì Coach' : 'üé≠ Character'}:</strong> ${section.content}`;
                    messageWrapper.appendChild(sectionDiv);
                });
                
                chatContainer.appendChild(messageWrapper);
            }
            
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // AGGRESSIVE: Much more sensitive coach detection
        function hybridDetectCoachSpeaking(text, conversationContext = null) {
            const lowerText = text.toLowerCase().trim();
            
            // PHASE 1: OBVIOUS coach self-identification (MOST OBVIOUS)
            const coachSelfId = [
                'i am a coach', 'i\'m a coach', 'i am the coach', 'i\'m the coach',
                'i am your coach', 'i\'m your coach', 'i am a female coach', 'i am a male coach',
                'coach here', 'coach speaking', 'coach again', 'as the coach',
                'this is the coach', 'hi, i\'m the coach', 'hello, i\'m the coach'
            ];
            
            for (let phrase of coachSelfId) {
                if (lowerText.includes(phrase)) {
                    addDebugInfo(`üö® COACH SELF-ID: "${phrase}"`);
                    return true;
                }
            }
            
            // PHASE 2: Explicit markers
            const explicitMarkers = [
                '**coach**', '**coach:', '[coach]', '(coach)', 
                '*coach*', 'coach:', '**coach mode**', '*coach mode*'
            ];
            
            for (let marker of explicitMarkers) {
                if (lowerText.includes(marker)) {
                    addDebugInfo(`‚úÖ EXPLICIT MARKER: "${marker}"`);
                    return true;
                }
            }
            
            // PHASE 3: AGGRESSIVE coaching activities detection
            const strongCoachingIndicators = [
                'watch a video', 'watch that video', 'watch the video', 'video about',
                'technique', 'strategy', 'approach', 'method', 'skill',
                'practice', 'exercise', 'lesson', 'step', 'tip',
                'better way', 'helpful way', 'useful way', 'different way',
                'let me help', 'help you', 'show you', 'teach you',
                'learn', 'understand', 'improve', 'develop',
                'guidance', 'advice', 'suggestion', 'recommendation'
            ];
            
            let strongIndicatorCount = 0;
            let foundIndicators = [];
            
            for (let indicator of strongCoachingIndicators) {
                if (lowerText.includes(indicator)) {
                    strongIndicatorCount++;
                    foundIndicators.push(indicator);
                }
            }
            
            if (strongIndicatorCount >= 1) {
                addDebugInfo(`üéØ STRONG COACHING INDICATORS (${strongIndicatorCount}): ${foundIndicators.join(', ')}`);
                return true;
            }
            
            // PHASE 4: Teaching/guidance language patterns
            const teachingPatterns = [
                'would you like to', 'do you want to', 'ready to',
                'let\'s try', 'how about', 'what if you',
                'here\'s what', 'this is how', 'try this',
                'notice how', 'see how', 'observe',
                'important to', 'key is', 'secret is',
                'remember to', 'don\'t forget', 'make sure'
            ];
            
            let teachingCount = 0;
            let teachingFound = [];
            
            for (let pattern of teachingPatterns) {
                if (lowerText.includes(pattern)) {
                    teachingCount++;
                    teachingFound.push(pattern);
                }
            }
            
            if (teachingCount >= 1 && text.length > 50) { // Longer responses with teaching language
                addDebugInfo(`üéì TEACHING PATTERNS (${teachingCount}): ${teachingFound.join(', ')}`);
                return true;
            }
            
            // PHASE 5: Contextual analysis (user state + response type)
            let contextScore = 0;
            let contextReasons = [];
            
            if (conversationContext && conversationContext.lastUserMessage) {
                const userMsg = conversationContext.lastUserMessage.toLowerCase();
                
                // User confusion/help-seeking + helpful response
                if ((userMsg.includes('confused') || userMsg.includes('don\'t understand') || 
                     userMsg.includes('help') || userMsg.includes('stuck') || userMsg.includes('ready')) &&
                    (lowerText.includes('let me') || lowerText.includes('here\'s') || 
                     lowerText.includes('try') || lowerText.includes('good'))) {
                    contextScore += 3;
                    contextReasons.push('User needs help ‚Üí guidance response');
                }
                
                // Escalation + de-escalation response
                if ((userMsg.includes('upset') || userMsg.includes('angry') || 
                     userMsg.includes('frustrated')) &&
                    (lowerText.includes('notice') || lowerText.includes('better') || 
                     lowerText.includes('way to') || lowerText.includes('calm'))) {
                    contextScore += 3;
                    contextReasons.push('Emotional situation ‚Üí coaching response');
                }
            }
            
            // PHASE 6: Meta-conversation indicators
            const metaPatterns = [
                'conversation has', 'situation like', 'what just happened',
                'good job', 'excellent', 'well done', 'nice work',
                'next step', 'continue', 'move forward',
                'practice what', 'use what', 'apply what'
            ];
            
            for (let meta of metaPatterns) {
                if (lowerText.includes(meta)) {
                    contextScore += 2;
                    contextReasons.push(`Meta-commentary: "${meta}"`);
                }
            }
            
            // DECISION LOGIC - Much more sensitive
            const totalScore = contextScore;
            const isCoach = totalScore >= 2;
            
            if (isCoach) {
                addDebugInfo(`üéØ CONTEXTUAL COACH (score: ${totalScore}) - ${contextReasons.join(', ')}`);
            } else {
                addDebugInfo(`üé≠ CHARACTER VOICE (score: ${totalScore}) - ${contextReasons.length > 0 ? contextReasons.join(', ') : 'No coaching indicators found'}`);
            }
            
            return isCoach;
        }

        // HYBRID: Enhanced splitting with contextual awareness
        function hybridSplitCoachAndCharacter(text) {
            addDebugInfo(`üîç ANALYZING FULL TEXT (${text.length} chars): "${text.substring(0, 100)}..."`);
            
            // Build conversation context for smarter detection
            const conversationContext = {
                lastUserMessage: lastUserMessage,
                conversationTurn: conversationTurn,
                recentHistory: conversationHistory.slice(-4) // Last 4 exchanges
            };
            
            // Check for explicit section markers first
            const explicitSectionPattern = /(\*\*coach\*\*:|\[coach\]|\*coach\*:|\*\*coach mode\*\*:)/gi;
            
            if (explicitSectionPattern.test(text)) {
                addDebugInfo('üìç EXPLICIT SECTION MARKERS found - using marker-based splitting');
                return splitByExplicitMarkers(text);
            }
            
            // For no explicit markers, use hybrid contextual analysis
            const paragraphs = text.split(/\n\n+/);
            if (paragraphs.length > 1) {
                addDebugInfo(`üìÑ MULTIPLE PARAGRAPHS detected (${paragraphs.length}) - analyzing each with context`);
                return splitParagraphsWithContext(paragraphs, conversationContext);
            }
            
            // Single paragraph - analyze sentences with context
            const sentences = text.split(/[.!?]+(?=\s+[A-Z])/);
            if (sentences.length > 2) {
                addDebugInfo(`üìù MULTIPLE SENTENCES detected (${sentences.length}) - analyzing with context`);
                return splitSentencesWithContext(sentences, conversationContext);
            }
            
            // Single sentence/paragraph - classify as whole with full context
            const isCoach = hybridDetectCoachSpeaking(text, conversationContext);
            const result = [{ type: isCoach ? 'coach' : 'character', content: text.trim() }];
            addDebugInfo(`üéØ SINGLE SECTION classified as: ${result[0].type} (contextual analysis)`);
            return result;
        }

        function splitByExplicitMarkers(text) {
            const markers = /(\*\*coach\*\*:|\[coach\]|\*coach\*:|\*\*coach mode\*\*:|\*stepping out of character\*|\*as your coach\*)/gi;
            const parts = text.split(markers);
            const sections = [];
            let currentType = 'character'; // Default to character
            
            for (let i = 0; i < parts.length; i++) {
                const part = parts[i].trim();
                if (!part) continue;
                
                if (markers.test(part)) {
                    currentType = 'coach';
                    continue;
                }
                
                if (part.length > 0) {
                    sections.push({ type: currentType, content: part });
                    // After a coach section, return to character unless another marker found
                    if (currentType === 'coach') currentType = 'character';
                }
            }
            
            return sections.length > 0 ? sections : [{ type: 'character', content: text }];
        }

        function splitParagraphsWithContext(paragraphs, conversationContext) {
            const sections = [];
            
            for (let paragraph of paragraphs) {
                const trimmed = paragraph.trim();
                if (!trimmed) continue;
                
                const isCoach = hybridDetectCoachSpeaking(trimmed, conversationContext);
                sections.push({ 
                    type: isCoach ? 'coach' : 'character', 
                    content: trimmed 
                });
            }
            
            return sections.length > 0 ? sections : [{ type: 'character', content: paragraphs.join('\n\n') }];
        }

        function splitSentencesWithContext(sentences, conversationContext) {
            const sections = [];
            let currentSection = null;
            
            for (let sentence of sentences) {
                const trimmed = sentence.trim();
                if (!trimmed) continue;
                
                const isCoach = hybridDetectCoachSpeaking(trimmed, conversationContext);
                const type = isCoach ? 'coach' : 'character';
                
                if (!currentSection || currentSection.type !== type) {
                    if (currentSection) sections.push(currentSection);
                    currentSection = { type: type, content: trimmed };
                } else {
                    currentSection.content += '. ' + trimmed;
                }
            }
            
            if (currentSection) sections.push(currentSection);
            
            return sections.length > 0 ? sections : [{ type: 'character', content: sentences.join('. ') }];
        }

        // Manual override functions - always available
        function forceVoice(voiceType) {
            pendingVoiceOverride = voiceType;
            const detectedVoiceSpan = document.getElementById('detectedVoice');
            if (detectedVoiceSpan) {
                detectedVoiceSpan.textContent = voiceType.toUpperCase();
            }
            
            // Replay the last response with forced voice
            if (lastClaudeResponse) {
                const sections = [{ type: voiceType, content: lastClaudeResponse }];
                showStatus(`üîß Replaying with ${voiceType.toUpperCase()} voice (manual override)`, 'info');
                addDebugInfo(`üîß MANUAL OVERRIDE: Forced ${voiceType.toUpperCase()} voice for: "${lastClaudeResponse.substring(0, 50)}..."`);
                playMultipleVoiceSections(sections);
            }
        }

        function useDetectedVoice() {
            // Replay with originally detected voice
            if (lastClaudeResponse) {
                const sections = hybridSplitCoachAndCharacter(lastClaudeResponse);
                const detectedType = sections.length > 0 ? sections[0].type : 'character';
                
                const detectedVoiceSpan = document.getElementById('detectedVoice');
                if (detectedVoiceSpan) {
                    detectedVoiceSpan.textContent = detectedType.toUpperCase() + ' (AUTO)';
                }
                
                showStatus(`‚úÖ Using detected ${detectedType.toUpperCase()} voice`, 'info');
                addDebugInfo(`‚úÖ AUTO DETECT: Using detected ${detectedType.toUpperCase()} voice`);
                playMultipleVoiceSections(sections);
            }
        }

        function updateVoiceOverrideDisplay(detectedType) {
            const detectedVoiceSpan = document.getElementById('detectedVoice');
            if (detectedVoiceSpan) {
                detectedVoiceSpan.textContent = detectedType.toUpperCase() + ' (AUTO)';
            }
        }

        function initializeSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                return false;
            }
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            
            recognition.onstart = function() {
                const speechIndicator = document.getElementById('speechIndicator');
                if (speechIndicator) {
                    speechIndicator.textContent = 'üé§ Listening... Speak now!';
                    speechIndicator.style.display = 'block';
                }
                showStatus('üé§ Listening for your voice...', 'success');
            };
            
            recognition.onresult = function(event) {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                if (interimTranscript) {
                    const speechIndicator = document.getElementById('speechIndicator');
                    if (speechIndicator) {
                        speechIndicator.textContent = `üé§ Hearing: "${interimTranscript}"`;
                    }
                }
                
                if (finalTranscript) {
                    const userInput = document.getElementById('userInput');
                    if (userInput) {
                        const currentText = userInput.value;
                        userInput.value = currentText + finalTranscript + ' ';
                        showStatus(`‚úÖ Added: "${finalTranscript}"`, 'success');
                    }
                }
            };
            
            recognition.onerror = function(event) {
                let errorMessage = 'Speech recognition error: ';
                switch(event.error) {
                    case 'not-allowed':
                        errorMessage += 'Microphone permission denied.';
                        const microphoneHelp = document.getElementById('microphoneHelp');
                        if (microphoneHelp) {
                            microphoneHelp.style.display = 'block';
                        }
                        break;
                    case 'no-speech':
                        errorMessage += 'No speech detected.';
                        break;
                    default:
                        errorMessage += event.error;
                }
                showStatus(errorMessage, 'error');
                stopSpeechRecognition();
            };
            
            recognition.onend = function() {
                if (isRecording) {
                    stopSpeechRecognition();
                }
            };
            
            return true;
        }

        async function toggleSpeechRecognition() {
            if (!recognition) {
                showStatus('Speech recognition not supported. Try Chrome, Edge, or Safari.', 'error');
                return;
            }
            
            if (isRecording) {
                stopSpeechRecognition();
            } else {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    stream.getTracks().forEach(track => track.stop());
                    startSpeechRecognition();
                } catch (error) {
                    if (error.name === 'NotAllowedError') {
                        showStatus('‚ùå Microphone access denied. Please allow microphone access.', 'error');
                        const microphoneHelp = document.getElementById('microphoneHelp');
                        if (microphoneHelp) {
                            microphoneHelp.style.display = 'block';
                        }
                    } else {
                        showStatus(`‚ùå Microphone error: ${error.message}`, 'error');
                    }
                }
            }
        }
        
        function startSpeechRecognition() {
            isRecording = true;
            const speechBtn = document.getElementById('speechBtn');
            const speechIndicator = document.getElementById('speechIndicator');
            
            if (speechBtn) {
                speechBtn.textContent = 'üõë Stop Speaking';
                speechBtn.classList.add('recording');
            }
            
            if (speechIndicator) {
                speechIndicator.style.display = 'block';
                speechIndicator.textContent = 'üé§ Starting microphone...';
            }
            
            try {
                recognition.start();
                showStatus('üé§ Starting speech recognition...', 'info');
            } catch (error) {
                showStatus(`Failed to start speech recognition: ${error.message}`, 'error');
                stopSpeechRecognition();
            }
        }
        
        function stopSpeechRecognition() {
            isRecording = false;
            const speechBtn = document.getElementById('speechBtn');
            const speechIndicator = document.getElementById('speechIndicator');
            
            if (speechBtn) {
                speechBtn.textContent = 'üé§ Start Speaking';
                speechBtn.classList.remove('recording');
            }
            
            if (speechIndicator) {
                speechIndicator.style.display = 'none';
            }
            
            if (recognition) {
                try {
                    recognition.stop();
                } catch (error) {
                    console.error('Error stopping recognition:', error);
                }
            }
            showStatus('Stopped listening', 'info');
        }

        async function checkMicrophonePermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                showStatus('‚úÖ Microphone access granted!', 'success');
                const microphoneHelp = document.getElementById('microphoneHelp');
                if (microphoneHelp) {
                    microphoneHelp.style.display = 'none';
                }
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) {
                    speechBtn.disabled = false;
                }
            } catch (error) {
                showStatus(`‚ùå Microphone error: ${error.message}`, 'error');
            }
        }

        async function makeAPICallWithCorsfix(url, options) {
            try {
                showStatus("Using Corsfix professional service...", "info");
                addDebugInfo(`üåê CORSFIX REQUEST: ${options.method || 'GET'} ${url}`);
                
                const proxyUrl = `https://proxy.corsfix.com/?${url}`;
                addDebugInfo(`üîó Proxy URL: ${proxyUrl}`);
                
                const response = await fetch(proxyUrl, {
                    method: options.method || "GET",
                    headers: {
                        ...options.headers,
                        "x-corsfix-headers": JSON.stringify({
                            Origin: "",
                        }),
                    },
                    body: options.body || null,
                });

                addDebugInfo(`üì° Response status: ${response.status} ${response.statusText}`);

                if (!response.ok) {
                    const errorText = await response.text();
                    addDebugInfo(`‚ùå Error response: ${errorText}`);
                    throw new Error(`HTTP ${response.status}: ${errorText}`);
                }

                return response;
            } catch (error) {
                addDebugInfo(`üö® CORSFIX ERROR: ${error.message}`);
                
                if (error.message.includes('Failed to fetch')) {
                    showStatus(`‚ùå Network error: Check internet connection and try again`, "error");
                    throw new Error('Network connection failed - check your internet and try again');
                } else {
                    showStatus(`‚ùå Corsfix service error: ${error.message}`, "error");
                    throw error;
                }
            }
        }

        // FIXED: Better system prompt that enforces clearer coach/character distinctions
        async function makeClaudeRequest(userMessage, systemPrompt) {
            if (corsMethod === 'demo') {
                await new Promise(resolve => setTimeout(resolve, 1500));
                
                const scenarioContent = document.getElementById('scenario').value.trim();
                if (!scenarioContent) {
                    return "Please enter your roleplay scenario and coach instructions first!";
                }
                
                // Demo responses with clearer coach markers
                const demoResponses = [
                    "I understand what you're looking for. Let me help you with that quest. **COACH:** This is a great example of how to establish clear objectives in roleplay scenarios. Notice how I'm acknowledging your request while staying in character.",
                    "Very interesting choice! Let me see what happens next in our story. \n\n**Coach mode:** I want to pause here briefly - you're doing well with making decisive choices. This kind of commitment to your character's actions really drives the narrative forward.",
                    "That sounds like a challenging situation indeed! **COACH:** This is exactly the type of complex scenario where you can practice problem-solving skills. Consider multiple approaches before deciding."
                ];
                
                return demoResponses[conversationTurn % demoResponses.length];
            }

            const claudeKey = document.getElementById('claudeKey').value;
            if (!claudeKey) {
                throw new Error('Claude API key is required');
            }

            // HYBRID: More natural system prompt that doesn't force artificial markers
            const enhancedSystemPrompt = `${systemPrompt}

NATURAL COACHING INTEGRATION:
- You have two modes: CHARACTER (staying in roleplay) and COACH (stepping out to guide/teach)
- Switch naturally between modes based on conversation flow and learning opportunities
- When coaching, use natural language like "Let me help you with this" or "Here's a better approach"
- Only use explicit markers like "**COACH:**" if the context really calls for it
- Coach about: communication techniques, roleplay strategies, emotional skills, conversation management
- Natural coaching moments: after conflicts, when user seems stuck, during learning opportunities
- Keep the roleplay feeling authentic and flowing

Conversation context: Turn ${conversationTurn}
Last user message: "${lastUserMessage}"

Scenario: ${document.getElementById('scenario').value}`;

            const requestData = {
                model: 'claude-3-5-sonnet-20241022',
                max_tokens: 1000,
                system: enhancedSystemPrompt,
                messages: [...conversationHistory, { role: "user", content: userMessage }]
            };

            const response = await makeAPICallWithCorsfix('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': claudeKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify(requestData)
            });

            const data = await response.json();
            return data.content[0].text;
        }

        async function makeElevenLabsRequest(text, isCoach = false) {
            addDebugInfo(`VOICE REQUEST: ${isCoach ? 'COACH' : 'CHARACTER'} voice for: "${text.substring(0, 50)}..."`);
            
            if (corsMethod === 'demo') {
                // Create demo audio with different characteristics
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const duration = Math.min(text.length / 20, 3); // Variable duration based on text length
                const sampleRate = audioContext.sampleRate;
                const frameCount = duration * sampleRate;
                
                const audioBuffer = audioContext.createBuffer(1, frameCount, sampleRate);
                const channelData = audioBuffer.getChannelData(0);
                
                // Different audio patterns for coach vs character
                const frequency = isCoach ? 800 : 400;
                const pattern = isCoach ? 2 : 1; // Coach has more complex pattern
                
                for (let i = 0; i < frameCount; i++) {
                    const t = i / sampleRate;
                    channelData[i] = Math.sin(2 * Math.PI * frequency * t * pattern) * 0.1 * Math.exp(-t / duration * 2);
                }
                
                addDebugInfo(`Generated ${isCoach ? 'COACH' : 'CHARACTER'} demo audio (${duration.toFixed(1)}s)`);
                return new Blob([new ArrayBuffer(1024)], { type: 'audio/mpeg' });
            }

            const elevenKey = document.getElementById('elevenKey').value;
            if (!elevenKey) {
                throw new Error('ElevenLabs API key is required');
            }
            
            let voiceId;
            if (isCoach) {
                const customCoachVoice = document.getElementById('customCoachVoice').value;
                voiceId = customCoachVoice || selectedCoachVoice;
                addDebugInfo(`Using COACH voice: ${voiceId}`);
            } else {
                const customCharacterVoice = document.getElementById('customCharacterVoice').value;
                voiceId = customCharacterVoice || selectedCharacterVoice;
                addDebugInfo(`Using CHARACTER voice: ${voiceId}`);
            }
            
            const requestData = {
                text: text,
                model_id: "eleven_monolingual_v1",
                voice_settings: {
                    stability: isCoach ? 0.8 : 0.5,
                    similarity_boost: isCoach ? 0.9 : 0.75,
                    style: isCoach ? 0.2 : 0.0,
                    use_speaker_boost: true
                }
            };

            const response = await makeAPICallWithCorsfix(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                method: 'POST',
                headers: {
                    'Accept': 'audio/mpeg',
                    'Content-Type': 'application/json',
                    'xi-api-key': elevenKey
                },
                body: JSON.stringify(requestData)
            });

            return response.blob();
        }

        async function playMultipleVoiceSections(textSections) {
            addDebugInfo(`PLAYING ${textSections.length} VOICE SECTIONS`);
            
            const elevenKey = document.getElementById('elevenKey').value;
            if (!elevenKey && corsMethod !== 'demo') {
                showStatus('‚úÖ Response received! Add ElevenLabs key for speech.', 'success');
                return;
            }

            showStatus('Converting to speech with voice switching...', 'info');
            
            for (let i = 0; i < textSections.length; i++) {
                const section = textSections[i];
                const isCoach = section.type === 'coach';
                
                addDebugInfo(`Playing section ${i + 1}/${textSections.length}: ${isCoach ? 'COACH' : 'CHARACTER'}`);
                
                try {
                    const audioBlob = await makeElevenLabsRequest(section.content, isCoach);
                    
                    if (audioBlob) {
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audioPlayer = document.getElementById('audioPlayer');
                        const audioControls = document.getElementById('audioControls');
                        
                        if (audioPlayer && audioControls) {
                            audioPlayer.src = audioUrl;
                            audioControls.style.display = 'flex';
                            currentAudio = audioPlayer;
                            
                            const voiceType = isCoach ? 'COACH' : 'CHARACTER';
                            showStatus(`üéµ Playing ${voiceType} voice (${i + 1}/${textSections.length})...`, 'success');
                            
                            await new Promise((resolve) => {
                                audioPlayer.onended = resolve;
                                audioPlayer.onerror = resolve;
                                audioPlayer.play().catch(resolve);
                            });
                            
                            if (i < textSections.length - 1) {
                                await new Promise(resolve => setTimeout(resolve, 500));
                            }
                        }
                    }
                } catch (voiceError) {
                    showStatus(`Voice synthesis failed for section ${i + 1}: ${voiceError.message}`, 'error');
                    updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                }
            }
            
            showStatus('‚úÖ All voice sections complete!', 'success');
        }

        async function testCorsProxy() {
            showStatus('Testing CORS proxy connection...', 'info');
            addDebugInfo('üß™ TESTING CORS PROXY CONNECTION');
            
            try {
                // Test with a simple public API first
                const testUrl = 'https://httpbin.org/get';
                const proxyUrl = `https://proxy.corsfix.com/?${testUrl}`;
                
                addDebugInfo(`üîó Testing proxy with: ${proxyUrl}`);
                
                const response = await fetch(proxyUrl, {
                    method: 'GET',
                    headers: {
                        "x-corsfix-headers": JSON.stringify({
                            Origin: "",
                        }),
                    }
                });
                
                addDebugInfo(`üì° Proxy response: ${response.status} ${response.statusText}`);
                
                if (response.ok) {
                    const data = await response.json();
                    addDebugInfo(`‚úÖ CORS proxy is working! Test response received.`);
                    showStatus('‚úÖ CORS proxy is working fine', 'success');
                    updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
                } else {
                    throw new Error(`Proxy returned ${response.status}: ${response.statusText}`);
                }
                
            } catch (error) {
                addDebugInfo(`‚ùå CORS PROXY TEST FAILED: ${error.message}`);
                showStatus(`‚ùå CORS proxy test failed: ${error.message}`, 'error');
                updateStatusIndicator(document.getElementById('corsStatus'), 'error');
                
                if (error.message.includes('Failed to fetch')) {
                    addDebugInfo('üí° This suggests a network connectivity issue');
                    showStatus('üí° Network issue detected - check your internet connection', 'error');
                }
            }
        }
            if (corsMethod === 'demo') {
                showStatus('‚úÖ Demo mode - all systems ready!', 'success');
                addMessage('Demo mode test: Hybrid voice detection with contextual analysis!');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                return;
            }

            const claudeKey = document.getElementById('claudeKey').value.trim();
            if (!claudeKey) {
                showStatus('Please enter Claude API key first', 'error');
                return;
            }
            
            // Validate API key format
            if (!claudeKey.startsWith('sk-ant-')) {
                showStatus('‚ùå Invalid Claude API key format. Should start with "sk-ant-"', 'error');
                return;
            }
            
            showStatus('Testing API connections...', 'info');
            addDebugInfo(`üîë Testing with Claude API key: ${claudeKey.substring(0, 12)}...`);
            
            try {
                const claudeResponse = await makeClaudeRequest('Say hello and then add a coach comment using natural language', 'Test the coach detection by responding as character then coach.');
                
                if (claudeResponse) {
                    showStatus('‚úÖ Claude API working!', 'success');
                    addMessage(claudeResponse);
                    updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                    addDebugInfo(`‚úÖ Claude response received: ${claudeResponse.length} characters`);
                }
                
                const elevenKey = document.getElementById('elevenKey').value.trim();
                if (elevenKey) {
                    addDebugInfo(`üîë Testing ElevenLabs key: ${elevenKey.substring(0, 8)}...`);
                    try {
                        const sections = hybridSplitCoachAndCharacter(claudeResponse);
                        await playMultipleVoiceSections(sections);
                        showStatus('‚úÖ Both APIs working perfectly!', 'success');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                    } catch (voiceError) {
                        addDebugInfo(`‚ùå ElevenLabs error: ${voiceError.message}`);
                        showStatus(`Claude works, but ElevenLabs failed: ${voiceError.message}`, 'error');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                    }
                } else {
                    showStatus('‚úÖ Claude API working! Add ElevenLabs key for voice.', 'success');
                }
            } catch (error) {
                addDebugInfo(`üö® TEST CONNECTION ERROR: ${error.message}`);
                showStatus(`‚ùå API test failed: ${error.message}`, 'error');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'error');
                
                // Provide specific troubleshooting
                if (error.message.includes('Network connection failed')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Check your internet connection');
                } else if (error.message.includes('401') || error.message.includes('403')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Invalid API key - check your Claude API key');
                } else if (error.message.includes('429')) {
                    addDebugInfo('üí° TROUBLESHOOTING: Rate limited - wait a moment and try again');
                } else {
                    addDebugInfo('üí° TROUBLESHOOTING: Try switching to Demo mode to test the interface');
                }
            }
        }

        async function sendMessage() {
            if (corsMethod !== 'demo') {
                const claudeKey = document.getElementById('claudeKey').value;
                if (!claudeKey) {
                    showStatus('Please enter Claude API key or switch to Demo mode', 'error');
                    return;
                }
            }

            const userInput = document.getElementById('userInput').value.trim();
            if (!userInput) {
                showStatus('Please enter a message', 'error');
                return;
            }

            const scenario = document.getElementById('scenario').value;
            showStatus('Sending message...', 'info');
            addMessage(userInput, true);
            
            // Store for contextual analysis
            lastUserMessage = userInput;
            conversationTurn++;
            addDebugInfo(`üìä CONVERSATION TURN: ${conversationTurn}, User said: "${userInput.substring(0, 50)}..."`);

            try {
                const systemPrompt = scenario || "You are engaged in a roleplay conversation. Also act as a coach who occasionally steps in to provide guidance. Keep responses natural and authentic - avoid forced markers unless necessary.";
                
                const claudeText = await makeClaudeRequest(userInput, systemPrompt);
                lastClaudeResponse = claudeText;
                
                addMessage(claudeText);
                
                if (corsMethod !== 'demo') {
                    conversationHistory.push({ role: "user", content: userInput });
                    conversationHistory.push({ role: "assistant", content: claudeText });
                    if (conversationHistory.length > 10) {
                        conversationHistory = conversationHistory.slice(-10);
                    }
                }

                // Use hybrid detection system
                const textSections = hybridSplitCoachAndCharacter(claudeText);
                addDebugInfo(`üé≠ FINAL SECTIONS: ${textSections.map(s => `${s.type}(${s.content.length}ch)`).join(', ')}`);
                
                // Update the always-visible override controls
                if (textSections.length === 1) {
                    updateVoiceOverrideDisplay(textSections[0].type);
                } else {
                    updateVoiceOverrideDisplay('MIXED');
                }
                
                // Play voices
                if (textSections.length > 1) {
                    showStatus(`üéµ Detected ${textSections.length} voice sections`, 'info');
                    await playMultipleVoiceSections(textSections);
                } else {
                    const isCoach = textSections[0].type === 'coach';
                    const elevenKey = document.getElementById('elevenKey').value;
                    
                    if (elevenKey || corsMethod === 'demo') {
                        const voiceType = isCoach ? 'COACH' : 'CHARACTER';
                        showStatus(`üéµ Converting to speech (${voiceType} voice)...`, 'info');
                        
                        try {
                            const audioBlob = await makeElevenLabsRequest(claudeText, isCoach);
                            
                            if (audioBlob) {
                                const audioUrl = URL.createObjectURL(audioBlob);
                                const audioPlayer = document.getElementById('audioPlayer');
                                const audioControls = document.getElementById('audioControls');
                                
                                if (audioPlayer && audioControls) {
                                    audioPlayer.src = audioUrl;
                                    audioControls.style.display = 'flex';
                                    audioPlayer.play().catch(console.error);
                                    currentAudio = audioPlayer;
                                    showStatus(`‚úÖ Playing ${voiceType} voice!`, 'success');
                                }
                            }
                        } catch (voiceError) {
                            showStatus(`Text received! Voice synthesis failed: ${voiceError.message}`, 'error');
                            updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                        }
                    } else {
                        showStatus('‚úÖ Response received! Add ElevenLabs key for speech.', 'success');
                    }
                }

                document.getElementById('userInput').value = '';
            } catch (error) {
                showStatus(`‚ùå Error: ${error.message}`, 'error');
                console.error('Full error:', error);
                updateStatusIndicator(document.getElementById('claudeStatus'), 'error');
            }
        }

        function stopAudio() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                showStatus('Audio stopped', 'info');
            }
        }

        function clearChat() {
            const chatContainer = document.getElementById('chatContainer');
            if (chatContainer) {
                chatContainer.innerHTML = '<p style="text-align: center; color: #666;">Start a conversation!</p>';
            }
            conversationHistory = [];
            conversationTurn = 0;
            lastUserMessage = '';
            lastClaudeResponse = '';
            pendingVoiceOverride = null;
            
            const audioControls = document.getElementById('audioControls');
            if (audioControls) {
                audioControls.style.display = 'none';
            }
            
            const voiceOverrideControls = document.getElementById('voiceOverrideControls');
            if (voiceOverrideControls) {
                voiceOverrideControls.style.display = 'none';
            }
            
            const debugContent = document.getElementById('debugContent');
            if (debugContent) {
                debugContent.innerHTML = '';
            }
            
            showStatus('Chat cleared - hybrid system reset', 'info');
            addDebugInfo('üîÑ Chat cleared - conversation context reset');
        }

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', function() {
            const speechAvailable = initializeSpeechRecognition();
            
            // CORS method selector
            document.querySelectorAll('input[name="corsMethod"]').forEach(radio => {
                radio.addEventListener('change', function() {
                    corsMethod = this.value;
                    const demoInfo = document.getElementById('demoInfo');
                    const apiSetup = document.getElementById('apiSetup');
                    
                    if (corsMethod === 'demo') {
                        if (demoInfo) demoInfo.style.display = 'block';
                        if (apiSetup) apiSetup.style.opacity = '0.5';
                        showStatus('Demo mode activated with fixed voice detection', 'info');
                        updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
                    } else {
                        if (demoInfo) demoInfo.style.display = 'none';
                        if (apiSetup) apiSetup.style.opacity = '1';
                        showStatus('Corsfix professional service selected', 'info');
                        updateStatusIndicator(document.getElementById('corsStatus'), '');
                    }
                });
            });

            // Character voice selection
            document.querySelectorAll('#characterVoices .voice-option').forEach(option => {
                option.addEventListener('click', function() {
                    document.querySelectorAll('#characterVoices .voice-option').forEach(o => o.classList.remove('selected'));
                    this.classList.add('selected');
                    selectedCharacterVoice = this.dataset.voice;
                    showStatus(`Selected character voice: ${this.textContent}`, 'info');
                });
            });

            // Coach voice selection
            document.querySelectorAll('#coachVoices .voice-option').forEach(option => {
                option.addEventListener('click', function() {
                    document.querySelectorAll('#coachVoices .voice-option').forEach(o => o.classList.remove('coach-selected'));
                    this.classList.add('coach-selected');
                    selectedCoachVoice = this.dataset.voice;
                    showStatus(`Selected coach voice: ${this.textContent}`, 'info');
                });
            });

            // Enter key handler for sending messages
            const userInput = document.getElementById('userInput');
            if (userInput) {
                userInput.addEventListener('keypress', function(e) {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        sendMessage();
                    }
                });
            }

            // Status message and HTTPS check
            const isSecureContext = window.isSecureContext || location.protocol === 'https:';
            if (!speechAvailable) {
                showStatus('‚ö†Ô∏è Speech recognition not available. Use Chrome, Edge, or Safari.', 'error');
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) speechBtn.disabled = true;
            } else if (!isSecureContext) {
                showStatus('‚ö†Ô∏è Speech recognition requires HTTPS. Upload to GitHub Pages/Netlify for microphone access.', 'error');
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) speechBtn.disabled = true;
                const microphoneHelp = document.getElementById('microphoneHelp');
                if (microphoneHelp) microphoneHelp.style.display = 'block';
            } else {
                showStatus('Ready! Fixed voice detection - should work consistently now.', 'info');
            }
            
            // Initialize status indicators
            updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
        });
    </script>
</body>
</html>