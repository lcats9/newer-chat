<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claude Roleplay with Fixed Voice Detection</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        h1 {
            text-align: center;
            color: #4a5568;
            margin-bottom: 30px;
        }
        
        .api-setup {
            background: #f7fafc;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            border-left: 4px solid #4299e1;
        }
        
        .input-group {
            margin-bottom: 15px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 600;
            color: #2d3748;
        }
        
        input, textarea, select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 14px;
            transition: border-color 0.3s;
            box-sizing: border-box;
        }
        
        input:focus, textarea:focus, select:focus {
            outline: none;
            border-color: #4299e1;
        }
        
        button {
            background: linear-gradient(135deg, #4299e1, #3182ce);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            margin: 5px;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(66, 153, 225, 0.3);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        
        button.recording {
            background: linear-gradient(135deg, #e53e3e, #c53030);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .speech-indicator {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 8px;
            padding: 10px;
            margin: 10px 0;
            text-align: center;
            font-weight: 500;
            color: #856404;
        }
        
        .chat-container {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            max-height: 400px;
            overflow-y: auto;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
        }
        
        .user-message {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
        }
        
        .claude-message {
            background: #f3e5f5;
            border-left: 4px solid #9c27b0;
        }
        
        .coach-section {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            margin: 5px 0;
            padding: 8px;
            border-radius: 5px;
            font-style: italic;
        }
        
        .character-section {
            background: #e8f5e8;
            border-left: 4px solid #4caf50;
            margin: 5px 0;
            padding: 8px;
            border-radius: 5px;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .status {
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-weight: 500;
        }
        
        .status.success { background: #d4e6f1; color: #1565c0; }
        .status.error { background: #ffebee; color: #c62828; }
        .status.info { background: #e8f5e8; color: #2e7d32; }
        
        .audio-controls {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-top: 10px;
        }
        
        audio {
            flex: 1;
            max-width: 300px;
        }
        
        .cors-info {
            background: #e8f5e8;
            border: 1px solid #4caf50;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            color: #2e7d32;
        }
        
        .proxy-selector {
            margin: 15px 0;
        }
        
        .proxy-option {
            margin: 8px 0;
            padding: 10px;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
        }
        
        .demo-mode {
            background: #e1f5fe;
            border: 1px solid #0288d1;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        
        .voice-selector {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 8px;
            margin-top: 10px;
        }
        
        .voice-option {
            padding: 8px 12px;
            background: #f0f0f0;
            border: 1px solid #ddd;
            border-radius: 5px;
            cursor: pointer;
            text-align: center;
            transition: background-color 0.2s;
            font-size: 12px;
        }
        
        .voice-option:hover {
            background: #e0e0e0;
        }
        
        .voice-option.selected {
            background: #4299e1;
            color: white;
        }
        
        .voice-option.coach-selected {
            background: #9f7aea;
            color: white;
        }
        
        .microphone-help {
            background: #ffebee;
            border: 1px solid #f44336;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #c62828;
        }
        
        .api-help {
            background: #fff3cd;
            border: 1px solid #ffc107;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #856404;
        }
        
        .voice-section {
            background: #f8f9ff;
            border: 1px solid #d0d0ff;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        
        .connection-status {
            display: flex;
            gap: 10px;
            align-items: center;
            margin: 10px 0;
        }
        
        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ccc;
        }
        
        .status-indicator.connected {
            background: #4caf50;
            animation: pulse-green 2s infinite;
        }
        
        .status-indicator.error {
            background: #f44336;
        }
        
        @keyframes pulse-green {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .coach-instruction {
            background: #fff9e6;
            border: 1px solid #ffc107;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            color: #8b5000;
        }
        
        .debug-info {
            background: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            font-family: monospace;
            font-size: 12px;
            max-height: 150px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ Claude Roleplay with Fixed Voice Detection</h1>
        
        <div class="cors-info">
            <h3>‚úÖ Fixed Voice Detection Issues</h3>
            <p>Improved robust voice switching that doesn't degrade over time + better coach detection patterns.</p>
        </div>
        
        <div class="connection-status">
            <div class="status-indicator" id="corsStatus"></div>
            <span>CORS Proxy Status</span>
            <div class="status-indicator" id="claudeStatus"></div>
            <span>Claude API</span>
            <div class="status-indicator" id="elevenStatus"></div>
            <span>ElevenLabs API</span>
        </div>
        
        <div class="proxy-selector">
            <h3>üîß CORS Solutions</h3>
            <div class="proxy-option">
                <label>
                    <input type="radio" name="corsMethod" value="corsfix" checked> 
                    <strong>Corsfix Professional (Recommended)</strong>
                </label>
                <small>Professional service with reliable API access</small>
            </div>
            <div class="proxy-option">
                <label>
                    <input type="radio" name="corsMethod" value="demo"> 
                    <strong>Demo Mode (For Testing)</strong>
                </label>
                <small>Test interface with mock responses</small>
            </div>
        </div>
        
        <div class="demo-mode" id="demoInfo" style="display: none;">
            <h3>üéØ Demo Mode Active</h3>
            <p>This mode simulates API responses with fixed voice detection. Switch to Corsfix above to use real APIs.</p>
        </div>
        
        <div class="api-help">
            <h3>üìã API Key Instructions</h3>
            <p><strong>Claude API:</strong> Get your key from <a href="https://console.anthropic.com" target="_blank">console.anthropic.com</a> ‚Üí API Keys</p>
            <p><strong>ElevenLabs API:</strong> Get your key from <a href="https://elevenlabs.io/app/speech-synthesis" target="_blank">elevenlabs.io</a> ‚Üí Profile ‚Üí API Keys</p>
        </div>
        
        <div class="microphone-help" id="microphoneHelp" style="display: none;">
            <h3>üé§ Microphone Permission Help</h3>
            <p><strong>If speech recognition doesn't work:</strong></p>
            <ol>
                <li><strong>HTTPS Required:</strong> Upload to GitHub Pages, Netlify, or Vercel for microphone access</li>
                <li><strong>Chrome/Edge:</strong> Click the üé§ icon in address bar ‚Üí Allow microphone</li>
                <li><strong>Manual check:</strong> <button onclick="checkMicrophonePermission()" style="display: inline; padding: 5px 10px; margin: 0;">Test Microphone Access</button></li>
            </ol>
        </div>
        
        <div class="api-setup" id="apiSetup">
            <h3>API Configuration</h3>
            <div class="input-group">
                <label for="claudeKey">Claude API Key:</label>
                <input type="password" id="claudeKey" placeholder="sk-ant-... (get from console.anthropic.com)">
            </div>
            <div class="input-group">
                <label for="elevenKey">ElevenLabs API Key:</label>
                <input type="password" id="elevenKey" placeholder="Get from elevenlabs.io/app/speech-synthesis">
            </div>
            
            <div class="voice-section">
                <h4>üéØ Character Voice Selection:</h4>
                <label>Character Voice (for roleplay scenarios):</label>
                <div class="voice-selector" id="characterVoices">
                    <div class="voice-option selected" data-voice="pNInz6obpgDQGcFmaJgB">Adam</div>
                    <div class="voice-option" data-voice="21m00Tcm4TlvDq8ikWAM">Rachel</div>
                    <div class="voice-option" data-voice="AZnzlk1XvdvUeBnXmlld">Domi</div>
                    <div class="voice-option" data-voice="EXAVITQu4vr4xnSDxMaL">Bella</div>
                    <div class="voice-option" data-voice="ErXwobaYiN019PkySvjV">Antoni</div>
                    <div class="voice-option" data-voice="MF3mGyEYCl7XYWbV9V6O">Elli</div>
                </div>
                <input type="text" id="customCharacterVoice" placeholder="Or enter custom Character Voice ID" style="margin-top: 10px;">
            </div>
            
            <div class="voice-section">
                <h4>üéì Coach Voice Selection:</h4>
                <label>Coach Voice (detected automatically in responses):</label>
                <div class="voice-selector" id="coachVoices">
                    <div class="voice-option coach-selected" data-voice="21m00Tcm4TlvDq8ikWAM">Rachel</div>
                    <div class="voice-option" data-voice="pNInz6obpgDQGcFmaJgB">Adam</div>
                    <div class="voice-option" data-voice="AZnzlk1XvdvUeBnXmlld">Domi</div>
                    <div class="voice-option" data-voice="EXAVITQu4vr4xnSDxMaL">Bella</div>
                    <div class="voice-option" data-voice="ErXwobaYiN019PkySvjV">Antoni</div>
                    <div class="voice-option" data-voice="MF3mGyEYCl7XYWbV9V6O">Elli</div>
                </div>
                <input type="text" id="customCoachVoice" placeholder="Or enter custom Coach Voice ID" style="margin-top: 10px;">
            </div>
        </div>
        
        <div class="coach-instruction">
            <h4>üéì Fixed Voice Detection Features:</h4>
            <ul>
                <li><strong>Expanded Pattern Detection:</strong> More coaching phrases and flexible matching</li>
                <li><strong>Context Awareness:</strong> Better detection of coaching tone and content</li>
                <li><strong>Consistent System Prompts:</strong> Maintains clear coach/character distinctions</li>
                <li><strong>Debug Visibility:</strong> See exactly what's being detected (check console)</li>
            </ul>
        </div>
        
        <div class="input-group">
            <label for="scenario">Roleplay Scenario & Coach Instructions:</label>
            <textarea id="scenario" rows="4" placeholder="e.g., 'You are a friendly wizard helping me on a quest. You also act as a coach who steps in periodically to give me guidance on my roleplay choices. When coaching, ALWAYS use clear markers like **COACH:** or [Coach] or *Coach mode:* to indicate when you're stepping out of character.'"></textarea>
        </div>
        
        <div class="input-group">
            <label for="userInput">Your Message:</label>
            <textarea id="userInput" rows="2" placeholder="Type your message here..."></textarea>
        </div>
        
        <div class="controls">
            <button onclick="sendMessage()">Send & Speak</button>
            <button onclick="toggleSpeechRecognition()" id="speechBtn">üé§ Start Speaking</button>
            <button onclick="stopAudio()">Stop Audio</button>
            <button onclick="clearChat()">Clear Chat</button>
            <button onclick="testConnection()">Test APIs</button>
            <button onclick="toggleDebug()">Toggle Debug</button>
        </div>
        
        <div id="status"></div>
        
        <div id="speechIndicator" class="speech-indicator" style="display: none;">
            üé§ Listening... Speak now, then click "Stop Speaking" when done.
        </div>
        
        <div class="debug-info" id="debugInfo" style="display: none;">
            <strong>Voice Detection Debug:</strong>
            <div id="debugContent"></div>
        </div>
        
        <div class="chat-container" id="chatContainer">
            <p style="text-align: center; color: #666;">Set up your scenario with coach instructions, then start chatting!</p>
        </div>
        
        <div class="audio-controls" id="audioControls" style="display: none;">
            <audio controls id="audioPlayer"></audio>
        </div>
    </div>

    <script>
        let currentAudio = null;
        let conversationHistory = [];
        let recognition = null;
        let isRecording = false;
        let selectedCharacterVoice = 'pNInz6obpgDQGcFmaJgB';
        let selectedCoachVoice = '21m00Tcm4TlvDq8ikWAM';
        let corsMethod = 'corsfix';
        let debugMode = false;
        let conversationTurn = 0; // Track conversation progress

        function updateStatusIndicator(element, status) {
            if (element) {
                element.className = `status-indicator ${status}`;
            }
        }

        function showStatus(message, type = 'info') {
            const status = document.getElementById('status');
            if (status) {
                status.className = `status ${type}`;
                status.textContent = message;
                setTimeout(() => status.textContent = '', 10000);
            }
        }

        function addDebugInfo(message) {
            if (debugMode) {
                const debugContent = document.getElementById('debugContent');
                if (debugContent) {
                    const timestamp = new Date().toLocaleTimeString();
                    debugContent.innerHTML += `[${timestamp}] ${message}<br>`;
                    debugContent.scrollTop = debugContent.scrollHeight;
                }
            }
            console.log('üîç DEBUG:', message);
        }

        function toggleDebug() {
            debugMode = !debugMode;
            const debugInfo = document.getElementById('debugInfo');
            if (debugInfo) {
                debugInfo.style.display = debugMode ? 'block' : 'none';
                if (debugMode) {
                    addDebugInfo('Debug mode enabled - voice detection info will appear here');
                }
            }
        }

        function addMessage(content, isUser = false) {
            const chatContainer = document.getElementById('chatContainer');
            if (!chatContainer) return;
            
            if (isUser) {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'message user-message';
                messageDiv.innerHTML = `<strong>You:</strong> ${content}`;
                chatContainer.appendChild(messageDiv);
            } else {
                // Split and display coach/character sections visually
                const sections = improvedSplitCoachAndCharacter(content);
                const messageWrapper = document.createElement('div');
                messageWrapper.className = 'message claude-message';
                messageWrapper.innerHTML = '<strong>Claude:</strong>';
                
                sections.forEach(section => {
                    const sectionDiv = document.createElement('div');
                    sectionDiv.className = section.type === 'coach' ? 'coach-section' : 'character-section';
                    sectionDiv.innerHTML = `<strong>${section.type === 'coach' ? 'üéì Coach' : 'üé≠ Character'}:</strong> ${section.content}`;
                    messageWrapper.appendChild(sectionDiv);
                });
                
                chatContainer.appendChild(messageWrapper);
            }
            
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // FIXED: Much more robust coach detection
        function improvedDetectCoachSpeaking(text) {
            const lowerText = text.toLowerCase().trim();
            
            // Explicit coach markers (highest priority)
            const explicitMarkers = [
                '**coach**', '**coach:', '[coach]', '(coach)', 
                '*coach*', 'coach:', '**coach mode**', '*coach mode*',
                '*stepping out of character*', '*as your coach*',
                '**stepping out of character**', '**as your coach**',
                'coach here:', '*coach here*', '**coach here**'
            ];
            
            for (let marker of explicitMarkers) {
                if (lowerText.includes(marker)) {
                    addDebugInfo(`EXPLICIT COACH MARKER found: "${marker}" in text: "${text.substring(0, 50)}..."`);
                    return true;
                }
            }
            
            // Coaching language patterns (medium priority)
            const coachingPhrases = [
                'from a coaching perspective', 'as your coach', 'coaching moment',
                'let me step in here', 'stepping out of character',
                'from a guidance standpoint', 'coaching advice',
                'this is a good opportunity to', 'practice this technique',
                'notice how', 'this is exactly the kind of situation',
                'learning opportunity', 'skill development',
                'constructive feedback', 'improvement suggestion'
            ];
            
            for (let phrase of coachingPhrases) {
                if (lowerText.includes(phrase)) {
                    addDebugInfo(`COACHING PHRASE found: "${phrase}" in text: "${text.substring(0, 50)}..."`);
                    return true;
                }
            }
            
            // Meta-conversation indicators (lower priority, but important)
            const metaIndicators = [
                'ready to continue', 'practice these', 'apply the techniques',
                'we\'ve discussed', 'skill to practice', 'approach this differently',
                'roleplay technique', 'character development', 'story improvement'
            ];
            
            for (let indicator of metaIndicators) {
                if (lowerText.includes(indicator)) {
                    addDebugInfo(`META INDICATOR found: "${indicator}" in text: "${text.substring(0, 50)}..."`);
                    return true;
                }
            }
            
            // Context-based detection for longer conversations
            if (conversationTurn > 3) {
                // After several turns, be more sensitive to coaching language
                const contextualCoachPhrases = [
                    'let\'s try', 'you could', 'consider this', 'think about',
                    'alternative approach', 'different way', 'strategy here',
                    'reflection on', 'what if you', 'have you considered'
                ];
                
                // Check if multiple coaching indicators appear
                let coachingScore = 0;
                for (let phrase of contextualCoachPhrases) {
                    if (lowerText.includes(phrase)) coachingScore++;
                }
                
                if (coachingScore >= 2) {
                    addDebugInfo(`CONTEXTUAL COACHING detected (score: ${coachingScore}) in: "${text.substring(0, 50)}..."`);
                    return true;
                }
            }
            
            addDebugInfo(`NO COACHING detected in: "${text.substring(0, 50)}..."`);
            return false;
        }

        // FIXED: More intelligent splitting that handles mixed content better
        function improvedSplitCoachAndCharacter(text) {
            addDebugInfo(`ANALYZING FULL TEXT (${text.length} chars): "${text.substring(0, 100)}..."`);
            
            // First, check for explicit section markers
            const explicitSectionPattern = /(\*\*coach\*\*:|\[coach\]|\*coach\*:|\*\*coach mode\*\*:|\*stepping out of character\*|\*as your coach\*)/gi;
            
            if (explicitSectionPattern.test(text)) {
                addDebugInfo('EXPLICIT SECTION MARKERS found - using marker-based splitting');
                return splitByExplicitMarkers(text);
            }
            
            // For no explicit markers, use paragraph/sentence analysis
            const paragraphs = text.split(/\n\n+/);
            if (paragraphs.length > 1) {
                addDebugInfo(`MULTIPLE PARAGRAPHS detected (${paragraphs.length}) - analyzing each`);
                return splitByParagraphs(paragraphs);
            }
            
            // Single paragraph - analyze sentences
            const sentences = text.split(/[.!?]+(?=\s+[A-Z])/);
            if (sentences.length > 2) {
                addDebugInfo(`MULTIPLE SENTENCES detected (${sentences.length}) - analyzing each`);
                return splitBySentences(sentences);
            }
            
            // Single sentence/paragraph - classify as whole
            const isCoach = improvedDetectCoachSpeaking(text);
            const result = [{ type: isCoach ? 'coach' : 'character', content: text.trim() }];
            addDebugInfo(`SINGLE SECTION classified as: ${result[0].type}`);
            return result;
        }

        function splitByExplicitMarkers(text) {
            const markers = /(\*\*coach\*\*:|\[coach\]|\*coach\*:|\*\*coach mode\*\*:|\*stepping out of character\*|\*as your coach\*)/gi;
            const parts = text.split(markers);
            const sections = [];
            let currentType = 'character'; // Default to character
            
            for (let i = 0; i < parts.length; i++) {
                const part = parts[i].trim();
                if (!part) continue;
                
                if (markers.test(part)) {
                    currentType = 'coach';
                    continue;
                }
                
                if (part.length > 0) {
                    sections.push({ type: currentType, content: part });
                    // After a coach section, return to character unless another marker found
                    if (currentType === 'coach') currentType = 'character';
                }
            }
            
            return sections.length > 0 ? sections : [{ type: 'character', content: text }];
        }

        function splitByParagraphs(paragraphs) {
            const sections = [];
            
            for (let paragraph of paragraphs) {
                const trimmed = paragraph.trim();
                if (!trimmed) continue;
                
                const isCoach = improvedDetectCoachSpeaking(trimmed);
                sections.push({ 
                    type: isCoach ? 'coach' : 'character', 
                    content: trimmed 
                });
                addDebugInfo(`PARAGRAPH classified as: ${isCoach ? 'coach' : 'character'} - "${trimmed.substring(0, 50)}..."`);
            }
            
            return sections.length > 0 ? sections : [{ type: 'character', content: paragraphs.join('\n\n') }];
        }

        function splitBySentences(sentences) {
            const sections = [];
            let currentSection = null;
            
            for (let sentence of sentences) {
                const trimmed = sentence.trim();
                if (!trimmed) continue;
                
                const isCoach = improvedDetectCoachSpeaking(trimmed);
                const type = isCoach ? 'coach' : 'character';
                
                if (!currentSection || currentSection.type !== type) {
                    if (currentSection) sections.push(currentSection);
                    currentSection = { type: type, content: trimmed };
                } else {
                    currentSection.content += '. ' + trimmed;
                }
                
                addDebugInfo(`SENTENCE classified as: ${type} - "${trimmed.substring(0, 30)}..."`);
            }
            
            if (currentSection) sections.push(currentSection);
            
            return sections.length > 0 ? sections : [{ type: 'character', content: sentences.join('. ') }];
        }

        function initializeSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                return false;
            }
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            
            recognition.onstart = function() {
                const speechIndicator = document.getElementById('speechIndicator');
                if (speechIndicator) {
                    speechIndicator.textContent = 'üé§ Listening... Speak now!';
                    speechIndicator.style.display = 'block';
                }
                showStatus('üé§ Listening for your voice...', 'success');
            };
            
            recognition.onresult = function(event) {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                if (interimTranscript) {
                    const speechIndicator = document.getElementById('speechIndicator');
                    if (speechIndicator) {
                        speechIndicator.textContent = `üé§ Hearing: "${interimTranscript}"`;
                    }
                }
                
                if (finalTranscript) {
                    const userInput = document.getElementById('userInput');
                    if (userInput) {
                        const currentText = userInput.value;
                        userInput.value = currentText + finalTranscript + ' ';
                        showStatus(`‚úÖ Added: "${finalTranscript}"`, 'success');
                    }
                }
            };
            
            recognition.onerror = function(event) {
                let errorMessage = 'Speech recognition error: ';
                switch(event.error) {
                    case 'not-allowed':
                        errorMessage += 'Microphone permission denied.';
                        const microphoneHelp = document.getElementById('microphoneHelp');
                        if (microphoneHelp) {
                            microphoneHelp.style.display = 'block';
                        }
                        break;
                    case 'no-speech':
                        errorMessage += 'No speech detected.';
                        break;
                    default:
                        errorMessage += event.error;
                }
                showStatus(errorMessage, 'error');
                stopSpeechRecognition();
            };
            
            recognition.onend = function() {
                if (isRecording) {
                    stopSpeechRecognition();
                }
            };
            
            return true;
        }

        async function toggleSpeechRecognition() {
            if (!recognition) {
                showStatus('Speech recognition not supported. Try Chrome, Edge, or Safari.', 'error');
                return;
            }
            
            if (isRecording) {
                stopSpeechRecognition();
            } else {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    stream.getTracks().forEach(track => track.stop());
                    startSpeechRecognition();
                } catch (error) {
                    if (error.name === 'NotAllowedError') {
                        showStatus('‚ùå Microphone access denied. Please allow microphone access.', 'error');
                        const microphoneHelp = document.getElementById('microphoneHelp');
                        if (microphoneHelp) {
                            microphoneHelp.style.display = 'block';
                        }
                    } else {
                        showStatus(`‚ùå Microphone error: ${error.message}`, 'error');
                    }
                }
            }
        }
        
        function startSpeechRecognition() {
            isRecording = true;
            const speechBtn = document.getElementById('speechBtn');
            const speechIndicator = document.getElementById('speechIndicator');
            
            if (speechBtn) {
                speechBtn.textContent = 'üõë Stop Speaking';
                speechBtn.classList.add('recording');
            }
            
            if (speechIndicator) {
                speechIndicator.style.display = 'block';
                speechIndicator.textContent = 'üé§ Starting microphone...';
            }
            
            try {
                recognition.start();
                showStatus('üé§ Starting speech recognition...', 'info');
            } catch (error) {
                showStatus(`Failed to start speech recognition: ${error.message}`, 'error');
                stopSpeechRecognition();
            }
        }
        
        function stopSpeechRecognition() {
            isRecording = false;
            const speechBtn = document.getElementById('speechBtn');
            const speechIndicator = document.getElementById('speechIndicator');
            
            if (speechBtn) {
                speechBtn.textContent = 'üé§ Start Speaking';
                speechBtn.classList.remove('recording');
            }
            
            if (speechIndicator) {
                speechIndicator.style.display = 'none';
            }
            
            if (recognition) {
                try {
                    recognition.stop();
                } catch (error) {
                    console.error('Error stopping recognition:', error);
                }
            }
            showStatus('Stopped listening', 'info');
        }

        async function checkMicrophonePermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                showStatus('‚úÖ Microphone access granted!', 'success');
                const microphoneHelp = document.getElementById('microphoneHelp');
                if (microphoneHelp) {
                    microphoneHelp.style.display = 'none';
                }
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) {
                    speechBtn.disabled = false;
                }
            } catch (error) {
                showStatus(`‚ùå Microphone error: ${error.message}`, 'error');
            }
        }

        async function makeAPICallWithCorsfix(url, options) {
            try {
                showStatus("Using Corsfix professional service...", "info");
                
                const response = await fetch(`https://proxy.corsfix.com/?${url}`, {
                    method: options.method || "GET",
                    headers: {
                        ...options.headers,
                        "x-corsfix-headers": JSON.stringify({
                            Origin: "",
                        }),
                    },
                    body: options.body || null,
                });

                if (!response.ok) {
                    throw new Error(`Error: ${response.status} - ${await response.text()}`);
                }

                return response;
            } catch (error) {
                showStatus(`Corsfix service error: ${error.message}`, "error");
                throw error;
            }
        }

        // FIXED: Better system prompt that enforces clearer coach/character distinctions
        async function makeClaudeRequest(userMessage, systemPrompt) {
            if (corsMethod === 'demo') {
                await new Promise(resolve => setTimeout(resolve, 1500));
                
                const scenarioContent = document.getElementById('scenario').value.trim();
                if (!scenarioContent) {
                    return "Please enter your roleplay scenario and coach instructions first!";
                }
                
                // Demo responses with clearer coach markers
                const demoResponses = [
                    "I understand what you're looking for. Let me help you with that quest. **COACH:** This is a great example of how to establish clear objectives in roleplay scenarios. Notice how I'm acknowledging your request while staying in character.",
                    "Very interesting choice! Let me see what happens next in our story. \n\n**Coach mode:** I want to pause here briefly - you're doing well with making decisive choices. This kind of commitment to your character's actions really drives the narrative forward.",
                    "That sounds like a challenging situation indeed! **COACH:** This is exactly the type of complex scenario where you can practice problem-solving skills. Consider multiple approaches before deciding."
                ];
                
                return demoResponses[conversationTurn % demoResponses.length];
            }

            const claudeKey = document.getElementById('claudeKey').value;
            if (!claudeKey) {
                throw new Error('Claude API key is required');
            }

            // FIXED: Much more explicit system prompt
            const enhancedSystemPrompt = `${systemPrompt}

CRITICAL COACHING INSTRUCTIONS:
- You have two distinct modes: CHARACTER mode and COACH mode
- In CHARACTER mode: Stay fully in character for the roleplay scenario
- In COACH mode: Step out completely to provide guidance, tips, and feedback
- ALWAYS use explicit markers when switching to coach mode:
  - Use "**COACH:**" or "**Coach mode:**" or "[Coach]" at the start of coaching sections
  - Use phrases like "*stepping out of character*" or "*as your coach*"
- Make coaching sections clearly distinct from character dialogue
- Coach about: roleplay techniques, story development, character choices, communication skills
- Switch between modes naturally based on learning opportunities
- Keep responses engaging but not too long

Current conversation turn: ${conversationTurn}

Scenario: ${document.getElementById('scenario').value}`;

            const requestData = {
                model: 'claude-3-5-sonnet-20241022',
                max_tokens: 1000,
                system: enhancedSystemPrompt,
                messages: [...conversationHistory, { role: "user", content: userMessage }]
            };

            const response = await makeAPICallWithCorsfix('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': claudeKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify(requestData)
            });

            const data = await response.json();
            return data.content[0].text;
        }

        async function makeElevenLabsRequest(text, isCoach = false) {
            addDebugInfo(`VOICE REQUEST: ${isCoach ? 'COACH' : 'CHARACTER'} voice for: "${text.substring(0, 50)}..."`);
            
            if (corsMethod === 'demo') {
                // Create demo audio with different characteristics
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const duration = Math.min(text.length / 20, 3); // Variable duration based on text length
                const sampleRate = audioContext.sampleRate;
                const frameCount = duration * sampleRate;
                
                const audioBuffer = audioContext.createBuffer(1, frameCount, sampleRate);
                const channelData = audioBuffer.getChannelData(0);
                
                // Different audio patterns for coach vs character
                const frequency = isCoach ? 800 : 400;
                const pattern = isCoach ? 2 : 1; // Coach has more complex pattern
                
                for (let i = 0; i < frameCount; i++) {
                    const t = i / sampleRate;
                    channelData[i] = Math.sin(2 * Math.PI * frequency * t * pattern) * 0.1 * Math.exp(-t / duration * 2);
                }
                
                addDebugInfo(`Generated ${isCoach ? 'COACH' : 'CHARACTER'} demo audio (${duration.toFixed(1)}s)`);
                return new Blob([new ArrayBuffer(1024)], { type: 'audio/mpeg' });
            }

            const elevenKey = document.getElementById('elevenKey').value;
            if (!elevenKey) {
                throw new Error('ElevenLabs API key is required');
            }
            
            let voiceId;
            if (isCoach) {
                const customCoachVoice = document.getElementById('customCoachVoice').value;
                voiceId = customCoachVoice || selectedCoachVoice;
                addDebugInfo(`Using COACH voice: ${voiceId}`);
            } else {
                const customCharacterVoice = document.getElementById('customCharacterVoice').value;
                voiceId = customCharacterVoice || selectedCharacterVoice;
                addDebugInfo(`Using CHARACTER voice: ${voiceId}`);
            }
            
            const requestData = {
                text: text,
                model_id: "eleven_monolingual_v1",
                voice_settings: {
                    stability: isCoach ? 0.8 : 0.5,
                    similarity_boost: isCoach ? 0.9 : 0.75,
                    style: isCoach ? 0.2 : 0.0,
                    use_speaker_boost: true
                }
            };

            const response = await makeAPICallWithCorsfix(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                method: 'POST',
                headers: {
                    'Accept': 'audio/mpeg',
                    'Content-Type': 'application/json',
                    'xi-api-key': elevenKey
                },
                body: JSON.stringify(requestData)
            });

            return response.blob();
        }

        async function playMultipleVoiceSections(textSections) {
            addDebugInfo(`PLAYING ${textSections.length} VOICE SECTIONS`);
            
            const elevenKey = document.getElementById('elevenKey').value;
            if (!elevenKey && corsMethod !== 'demo') {
                showStatus('‚úÖ Response received! Add ElevenLabs key for speech.', 'success');
                return;
            }

            showStatus('Converting to speech with voice switching...', 'info');
            
            for (let i = 0; i < textSections.length; i++) {
                const section = textSections[i];
                const isCoach = section.type === 'coach';
                
                addDebugInfo(`Playing section ${i + 1}/${textSections.length}: ${isCoach ? 'COACH' : 'CHARACTER'}`);
                
                try {
                    const audioBlob = await makeElevenLabsRequest(section.content, isCoach);
                    
                    if (audioBlob) {
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audioPlayer = document.getElementById('audioPlayer');
                        const audioControls = document.getElementById('audioControls');
                        
                        if (audioPlayer && audioControls) {
                            audioPlayer.src = audioUrl;
                            audioControls.style.display = 'flex';
                            currentAudio = audioPlayer;
                            
                            const voiceType = isCoach ? 'COACH' : 'CHARACTER';
                            showStatus(`üéµ Playing ${voiceType} voice (${i + 1}/${textSections.length})...`, 'success');
                            
                            await new Promise((resolve) => {
                                audioPlayer.onended = resolve;
                                audioPlayer.onerror = resolve;
                                audioPlayer.play().catch(resolve);
                            });
                            
                            if (i < textSections.length - 1) {
                                await new Promise(resolve => setTimeout(resolve, 500));
                            }
                        }
                    }
                } catch (voiceError) {
                    showStatus(`Voice synthesis failed for section ${i + 1}: ${voiceError.message}`, 'error');
                    updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                }
            }
            
            showStatus('‚úÖ All voice sections complete!', 'success');
        }

        async function testConnection() {
            if (corsMethod === 'demo') {
                showStatus('‚úÖ Demo mode - all systems ready!', 'success');
                addMessage('Demo mode test: Fixed voice detection with clear coach/character separation!');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                return;
            }

            const claudeKey = document.getElementById('claudeKey').value;
            if (!claudeKey) {
                showStatus('Please enter Claude API key first', 'error');
                return;
            }
            
            showStatus('Testing API connections...', 'info');
            
            try {
                const claudeResponse = await makeClaudeRequest('Say hello and then add a coach comment using **COACH:** marker', 'Test the coach detection by responding as character then coach.');
                
                if (claudeResponse) {
                    showStatus('‚úÖ Claude API working!', 'success');
                    addMessage(claudeResponse);
                    updateStatusIndicator(document.getElementById('claudeStatus'), 'connected');
                }
                
                const elevenKey = document.getElementById('elevenKey').value;
                if (elevenKey) {
                    try {
                        const sections = improvedSplitCoachAndCharacter(claudeResponse);
                        await playMultipleVoiceSections(sections);
                        showStatus('‚úÖ Both APIs working perfectly!', 'success');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'connected');
                    } catch (voiceError) {
                        showStatus(`Claude works, but ElevenLabs failed: ${voiceError.message}`, 'error');
                        updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                    }
                } else {
                    showStatus('‚úÖ Claude API working! Add ElevenLabs key for voice.', 'success');
                }
            } catch (error) {
                showStatus(`‚ùå API test failed: ${error.message}`, 'error');
                updateStatusIndicator(document.getElementById('claudeStatus'), 'error');
            }
        }

        async function sendMessage() {
            if (corsMethod !== 'demo') {
                const claudeKey = document.getElementById('claudeKey').value;
                if (!claudeKey) {
                    showStatus('Please enter Claude API key or switch to Demo mode', 'error');
                    return;
                }
            }

            const userInput = document.getElementById('userInput').value.trim();
            if (!userInput) {
                showStatus('Please enter a message', 'error');
                return;
            }

            const scenario = document.getElementById('scenario').value;
            showStatus('Sending message...', 'info');
            addMessage(userInput, true);
            
            conversationTurn++; // Track conversation progress
            addDebugInfo(`CONVERSATION TURN: ${conversationTurn}`);

            try {
                const systemPrompt = scenario || "You are engaged in a roleplay conversation. Also act as a coach who occasionally steps in to provide guidance using **COACH:** markers. Keep responses engaging but not too long.";
                
                const claudeText = await makeClaudeRequest(userInput, systemPrompt);
                
                addMessage(claudeText);
                
                if (corsMethod !== 'demo') {
                    conversationHistory.push({ role: "user", content: userInput });
                    conversationHistory.push({ role: "assistant", content: claudeText });
                    if (conversationHistory.length > 10) {
                        conversationHistory = conversationHistory.slice(-10);
                    }
                }

                // Use improved splitting and play voices
                const textSections = improvedSplitCoachAndCharacter(claudeText);
                addDebugInfo(`FINAL SECTIONS: ${textSections.map(s => `${s.type}(${s.content.length}ch)`).join(', ')}`);
                
                if (textSections.length > 1) {
                    showStatus(`Detected ${textSections.length} voice sections`, 'info');
                    await playMultipleVoiceSections(textSections);
                } else {
                    const isCoach = textSections[0].type === 'coach';
                    const elevenKey = document.getElementById('elevenKey').value;
                    
                    if (elevenKey || corsMethod === 'demo') {
                        const voiceType = isCoach ? 'COACH' : 'CHARACTER';
                        showStatus(`Converting to speech (${voiceType} voice)...`, 'info');
                        
                        try {
                            const audioBlob = await makeElevenLabsRequest(claudeText, isCoach);
                            
                            if (audioBlob) {
                                const audioUrl = URL.createObjectURL(audioBlob);
                                const audioPlayer = document.getElementById('audioPlayer');
                                const audioControls = document.getElementById('audioControls');
                                
                                if (audioPlayer && audioControls) {
                                    audioPlayer.src = audioUrl;
                                    audioControls.style.display = 'flex';
                                    audioPlayer.play().catch(console.error);
                                    currentAudio = audioPlayer;
                                    showStatus(`‚úÖ Playing ${voiceType} voice!`, 'success');
                                }
                            }
                        } catch (voiceError) {
                            showStatus(`Text received! Voice synthesis failed: ${voiceError.message}`, 'error');
                            updateStatusIndicator(document.getElementById('elevenStatus'), 'error');
                        }
                    } else {
                        showStatus('‚úÖ Response received! Add ElevenLabs key for speech.', 'success');
                    }
                }

                document.getElementById('userInput').value = '';
            } catch (error) {
                showStatus(`‚ùå Error: ${error.message}`, 'error');
                console.error('Full error:', error);
                updateStatusIndicator(document.getElementById('claudeStatus'), 'error');
            }
        }

        function stopAudio() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                showStatus('Audio stopped', 'info');
            }
        }

        function clearChat() {
            const chatContainer = document.getElementById('chatContainer');
            if (chatContainer) {
                chatContainer.innerHTML = '<p style="text-align: center; color: #666;">Start a conversation!</p>';
            }
            conversationHistory = [];
            conversationTurn = 0; // Reset conversation tracking
            const audioControls = document.getElementById('audioControls');
            if (audioControls) {
                audioControls.style.display = 'none';
            }
            const debugContent = document.getElementById('debugContent');
            if (debugContent) {
                debugContent.innerHTML = '';
            }
            showStatus('Chat cleared and conversation reset', 'info');
            addDebugInfo('Chat cleared - conversation tracking reset');
        }

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', function() {
            const speechAvailable = initializeSpeechRecognition();
            
            // CORS method selector
            document.querySelectorAll('input[name="corsMethod"]').forEach(radio => {
                radio.addEventListener('change', function() {
                    corsMethod = this.value;
                    const demoInfo = document.getElementById('demoInfo');
                    const apiSetup = document.getElementById('apiSetup');
                    
                    if (corsMethod === 'demo') {
                        if (demoInfo) demoInfo.style.display = 'block';
                        if (apiSetup) apiSetup.style.opacity = '0.5';
                        showStatus('Demo mode activated with fixed voice detection', 'info');
                        updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
                    } else {
                        if (demoInfo) demoInfo.style.display = 'none';
                        if (apiSetup) apiSetup.style.opacity = '1';
                        showStatus('Corsfix professional service selected', 'info');
                        updateStatusIndicator(document.getElementById('corsStatus'), '');
                    }
                });
            });

            // Character voice selection
            document.querySelectorAll('#characterVoices .voice-option').forEach(option => {
                option.addEventListener('click', function() {
                    document.querySelectorAll('#characterVoices .voice-option').forEach(o => o.classList.remove('selected'));
                    this.classList.add('selected');
                    selectedCharacterVoice = this.dataset.voice;
                    showStatus(`Selected character voice: ${this.textContent}`, 'info');
                });
            });

            // Coach voice selection
            document.querySelectorAll('#coachVoices .voice-option').forEach(option => {
                option.addEventListener('click', function() {
                    document.querySelectorAll('#coachVoices .voice-option').forEach(o => o.classList.remove('coach-selected'));
                    this.classList.add('coach-selected');
                    selectedCoachVoice = this.dataset.voice;
                    showStatus(`Selected coach voice: ${this.textContent}`, 'info');
                });
            });

            // Enter key handler for sending messages
            const userInput = document.getElementById('userInput');
            if (userInput) {
                userInput.addEventListener('keypress', function(e) {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        sendMessage();
                    }
                });
            }

            // Status message and HTTPS check
            const isSecureContext = window.isSecureContext || location.protocol === 'https:';
            if (!speechAvailable) {
                showStatus('‚ö†Ô∏è Speech recognition not available. Use Chrome, Edge, or Safari.', 'error');
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) speechBtn.disabled = true;
            } else if (!isSecureContext) {
                showStatus('‚ö†Ô∏è Speech recognition requires HTTPS. Upload to GitHub Pages/Netlify for microphone access.', 'error');
                const speechBtn = document.getElementById('speechBtn');
                if (speechBtn) speechBtn.disabled = true;
                const microphoneHelp = document.getElementById('microphoneHelp');
                if (microphoneHelp) microphoneHelp.style.display = 'block';
            } else {
                showStatus('Ready! Fixed voice detection - should work consistently now.', 'info');
            }
            
            // Initialize status indicators
            updateStatusIndicator(document.getElementById('corsStatus'), 'connected');
        });
    </script>
</body>
</html>